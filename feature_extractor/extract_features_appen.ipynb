{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer \n",
    "import re\n",
    "from collections import Counter\n",
    "import liwc\n",
    "import math\n",
    "import json\n",
    "import os\n",
    "\n",
    "\n",
    "# Extract all\n",
    "\n",
    "def extract_all_features(reviews,min_doc_freq=2,saveto='review_features'):\n",
    "    \n",
    "    makedirectory(saveto)\n",
    "    \n",
    "    #struct\n",
    "    print('struct..')\n",
    "    struct_extract(reviews,saveto)\n",
    "        \n",
    "    #ugr\n",
    "    print('ugr..')\n",
    "    ugr_extract(reviews,min_doc_freq=min_doc_freq,saveto=saveto)\n",
    "    \n",
    "    #galc\n",
    "    print('galc')\n",
    "    galc_extract(reviews,saveto)\n",
    "    \n",
    "    #liwc\n",
    "    print('liwc')\n",
    "    liwc_extract(reviews,saveto)\n",
    "    \n",
    "    #inquirier\n",
    "    print('inq')\n",
    "    inq_extract(reviews,saveto)\n",
    "\n",
    "# STRUCT\n",
    " \n",
    "def struct_extract(reviews,saveto):\n",
    "\n",
    "    \"\"\"\n",
    "    review list(str): list of sentences \n",
    "    \"\"\"\n",
    "    \n",
    "    #initiate dataframe\n",
    "    results = pd.DataFrame(reviews)\n",
    "    results.columns = ['review']\n",
    "\n",
    "    #define local funcs\n",
    "    def avg_sent_length(string):\n",
    "        sentences = string.split('.')\n",
    "        sum_len = 0        \n",
    "        for i,s in enumerate(sentences):\n",
    "            sum_len += len(s)\n",
    "        return sum_len/len(sentences)\n",
    "\n",
    "    def per_of_q(string):\n",
    "    \n",
    "        num_q = string.count(\"?\")\n",
    "        new_string = string.replace(\"?\",\".\")\n",
    "        sentences = new_string.split(\".\")\n",
    "        \n",
    "        return num_q/len(sentences)\n",
    "    \n",
    "    #extract feats\n",
    "    results['length'] = results.review.apply(lambda x: len(x))\n",
    "    results['num_tokens'] = results.review.apply(lambda x: len(x.split(' ')))\n",
    "    results['num_sentences'] = results.review.apply(lambda x: x.count('.'))\n",
    "    results['avg_sent_len'] = results.review.apply(lambda x: avg_sent_length(x))\n",
    "    results['num_exclm_mark'] = results.review.apply(lambda x: x.count('!'))\n",
    "    results['ratio_q'] = results.review.apply(lambda x: per_of_q(x))\n",
    "    \n",
    "    #drop the review\n",
    "    results = results.drop(columns=['review'])\n",
    "    \n",
    "    #scale\n",
    "    results = results - results.min()\n",
    "    results = results / results.max()\n",
    "    results = results.fillna(0)\n",
    "    \n",
    "    #save file\n",
    "    results.to_csv('results/%s/struct_feats.csv'%saveto)\n",
    "\n",
    "\n",
    "# UGR \n",
    "\n",
    "def ugr_extract(reviews,min_doc_freq=0,saveto='review_features',chunk_n='0'):\n",
    "\n",
    "    print(len(reviews))\n",
    "\n",
    "    #remove stop_words \n",
    "    reviews_clean = []\n",
    "    stop_words = stopwords.words('english');\n",
    "    stop_words += [\"the\",\"and\",\"it\"]\n",
    "\n",
    "    print(\"cleaning .. \")\n",
    "\n",
    "    for r in reviews:\n",
    "        clean_r = r\n",
    "        for w in r.split(' '):\n",
    "            if w in stop_words: \n",
    "                clean_r = clean_r.replace(w,\"\");\n",
    "        reviews_clean.append(clean_r)\n",
    "\n",
    "    \n",
    "    print(\"tf-idf .. \")    \n",
    "\n",
    "    # calculate tf-idf\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    vectors = vectorizer.fit_transform(reviews_clean)\n",
    "    feature_names = vectorizer.get_feature_names()\n",
    "    dense = vectors.todense()\n",
    "    denselist = dense.tolist()\n",
    "\n",
    "    tf_idf = pd.DataFrame(denselist, columns=feature_names)\n",
    "\n",
    "\n",
    "    print(\"infrequent words .. \")\n",
    "\n",
    "    #remove infrequent words\n",
    "    cols = []\n",
    "    for c in tf_idf.columns:\n",
    "        col = tf_idf[c]\n",
    "        num_non_zer = 0\n",
    "        for r in col:\n",
    "            if r != 0:\n",
    "                num_non_zer += 1\n",
    "        if num_non_zer < min_doc_freq:\n",
    "            cols.append(c)\n",
    "    tf_idf_freq = tf_idf.drop(columns=cols)\n",
    "\n",
    "    print(\"scaling words .. \")\n",
    "\n",
    "    #scale\n",
    "    tf_idf_freq = tf_idf_freq - tf_idf_freq.min()\n",
    "    tf_idf_freq = tf_idf_freq / tf_idf_freq.max()\n",
    "    tf_idf_freq = tf_idf_freq.fillna(0)\n",
    "    \n",
    "    #save file\n",
    "    tf_idf_freq.to_csv('results/%s/tf_idf_freq_%s.csv'%(saveto,chunk_n))\n",
    "\n",
    "\n",
    "# GALC\n",
    "\n",
    "def galc_extract(reviews,saveto):\n",
    "    \n",
    "    # read galc dictionary\n",
    "    with open('helping/galc_dict.json') as json_file:\n",
    "        galc_dict = json.load(json_file)\n",
    "    \n",
    "    #init dataframe\n",
    "    galc_feature = pd.DataFrame(np.zeros((len(reviews),len(galc_dict))))\n",
    "    galc_feature.columns = list(galc_dict.keys())\n",
    "\n",
    "    def galc_vector_feature(review):\n",
    "        ps = PorterStemmer()\n",
    "        dic = dict.fromkeys(galc_dict.keys(),0)\n",
    "\n",
    "        for w in review.split(' '):\n",
    "            word = w.replace('.','')\n",
    "            stemmed = ps.stem(word)\n",
    "\n",
    "            for categ,words in galc_dict.items():\n",
    "                if stemmed in words:\n",
    "                    dic[categ] += 1\n",
    "\n",
    "        return dic.values()\n",
    "\n",
    "    for i,r in galc_feature.iterrows():\n",
    "        galc_feature.iloc[i] = galc_vector_feature(reviews[i])\n",
    "        \n",
    "    \n",
    "    #scale\n",
    "    galc_feature = galc_feature - galc_feature.min()\n",
    "    galc_feature = galc_feature / galc_feature.max()\n",
    "    galc_feature = galc_feature.fillna(0)\n",
    "\n",
    "    #Save file\n",
    "    galc_feature.to_csv('results/%s/GALC_Features.csv'%saveto)\n",
    "\n",
    "\n",
    "# LIWC \n",
    "\n",
    "def liwc_extract(reviews,saveto):\n",
    "    parse, category_names = liwc.load_token_parser('helping/LIWC2007_English100131.dic')\n",
    "\n",
    "    # define helpers\n",
    "    def tokenize(text):\n",
    "        # you may want to use a smarter tokenizer\n",
    "        for match in re.finditer(r'\\w+', text, re.UNICODE):\n",
    "            yield match.group(0)\n",
    "\n",
    "    def liwc_features(text):\n",
    "\n",
    "        dic = dict.fromkeys(category_names,0)\n",
    "\n",
    "        gettysburg_tokens = tokenize(text)\n",
    "        gettysburg_counts = Counter(category for token in gettysburg_tokens for category in parse(token))\n",
    "\n",
    "        for k,v in gettysburg_counts.items():\n",
    "            dic[k] = v\n",
    "\n",
    "        return dic.values()\n",
    "    \n",
    "    # init dataframe\n",
    "    liwc_feature = pd.DataFrame(np.zeros((len(reviews),len(category_names))))\n",
    "    liwc_feature.columns = category_names\n",
    "    \n",
    "    #extract feats\n",
    "    for i,r in liwc_feature.iterrows():\n",
    "        liwc_feature.iloc[i] = liwc_features(reviews[i])\n",
    "    \n",
    "    #scale\n",
    "    liwc_feature = liwc_feature - liwc_feature.min()\n",
    "    liwc_feature = liwc_feature / liwc_feature.max()\n",
    "    liwc_feature = liwc_feature.fillna(0)\n",
    "\n",
    "    #save file\n",
    "    liwc_feature.to_csv('results/%s/LIWC_Features.csv'%saveto)\n",
    "\n",
    "\n",
    "# INQURIER \n",
    "\n",
    "def inq_extract(reviews,saveto):\n",
    "    \n",
    "    #read inq\n",
    "    inq = pd.read_excel('helping/inquirerbasic.xls')\n",
    "    inq_categs = list(inq.columns)\n",
    "    \n",
    "    #init dataframe\n",
    "    inq_features = np.zeros((1,len(inq_categs)),dtype=int)\n",
    "\n",
    "    #extract features \n",
    "    for review in reviews:\n",
    "        inq_feat = dict.fromkeys(inq_categs,0)\n",
    "        for w in review.split(' '):\n",
    "            clean = w.strip().replace('.',\"\").replace(\"?\",'').replace(\",\",\"\").replace(\";\",'').upper()\n",
    "            # if the word exists in the dictionary\n",
    "            if len(inq[inq['Entry'] == clean]) > 0:\n",
    "                row = inq[inq['Entry']==clean].to_dict()\n",
    "                for k,v in row.items():\n",
    "                    vv = list(v.values())[0]\n",
    "                    if isinstance(vv,str):\n",
    "                        inq_feat[k] += 1\n",
    "\n",
    "        # convert the dict to one row features \n",
    "        inq_feat_row = np.array(list(inq_feat.values()),dtype=int).reshape((1,len(inq_categs)))\n",
    "\n",
    "        #combine with big matrix\n",
    "        inq_features = np.concatenate((inq_features,inq_feat_row),axis=0)\n",
    "    \n",
    "    \n",
    "    #scale\n",
    "    inq_features = pd.DataFrame(inq_features)\n",
    "    inq_features = inq_features - inq_features.min()\n",
    "    inq_features = inq_features / inq_features.max()\n",
    "    inq_features = inq_features.fillna(0)\n",
    "    \n",
    "    # save file\n",
    "    inq_features.to_csv('results/%s/inq_features.csv'%saveto)\n",
    "\n",
    "    \n",
    "####### HELPING FUNCIONS #######\n",
    "\n",
    "def makedirectory(name):\n",
    "    import os\n",
    "    if not os.path.isdir('results'):\n",
    "        os.mkdir('results') \n",
    "    if not os.path.isdir('results/%s'%name):\n",
    "        os.mkdir('results/%s'%name) \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "############################## DEMO #############################\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "hotel_labeled_data = pd.read_csv('apen/hotels/appen_translated - hotels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_unit_id</th>\n",
       "      <th>_golden</th>\n",
       "      <th>_unit_state</th>\n",
       "      <th>_trusted_judgments</th>\n",
       "      <th>_last_judgment_at</th>\n",
       "      <th>helpfulness</th>\n",
       "      <th>confidence</th>\n",
       "      <th>no</th>\n",
       "      <th>review</th>\n",
       "      <th>review_en</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2892106090</td>\n",
       "      <td>False</td>\n",
       "      <td>finalized</td>\n",
       "      <td>3</td>\n",
       "      <td>12/10/2020 22:54:18</td>\n",
       "      <td>helpful</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>23768</td>\n",
       "      <td>جيد. مديرة خدمة العملاء الانسه بشرى جدا متميزة...</td>\n",
       "      <td>good. Director of Customer Service Miss Bushra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2892106091</td>\n",
       "      <td>False</td>\n",
       "      <td>finalized</td>\n",
       "      <td>3</td>\n",
       "      <td>12/10/2020 22:54:18</td>\n",
       "      <td>helpful</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>173933</td>\n",
       "      <td>مقبول. موقع ممتاز. انتظار الاصنصير طويل لم يكن...</td>\n",
       "      <td>Acceptable. Excellent location. Waiting for a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2892106092</td>\n",
       "      <td>False</td>\n",
       "      <td>finalized</td>\n",
       "      <td>3</td>\n",
       "      <td>12/10/2020 22:54:18</td>\n",
       "      <td>helpful</td>\n",
       "      <td>0.6765</td>\n",
       "      <td>213748</td>\n",
       "      <td>جيد. الموقع ، طاقم العمل بشوشين ، مكان الافطار...</td>\n",
       "      <td>good. Location, staff Bchocan, place a small b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2892106093</td>\n",
       "      <td>False</td>\n",
       "      <td>finalized</td>\n",
       "      <td>3</td>\n",
       "      <td>12/10/2020 22:54:18</td>\n",
       "      <td>helpful</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>147649</td>\n",
       "      <td>“ممتازة”. كل شي رائع و نظيف و الاسرة نظيفة ومر...</td>\n",
       "      <td>\"Excellent\". Everything wonderful and clean an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2892106094</td>\n",
       "      <td>False</td>\n",
       "      <td>finalized</td>\n",
       "      <td>3</td>\n",
       "      <td>12/10/2020 22:55:10</td>\n",
       "      <td>helpful</td>\n",
       "      <td>0.6604</td>\n",
       "      <td>89990</td>\n",
       "      <td>“اروع فندق”. كل شي كان فندق حقيقة اكثر من رائع...</td>\n",
       "      <td>\"Finest hotel.\" Everything was more than a hot...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     _unit_id  _golden _unit_state  _trusted_judgments    _last_judgment_at  \\\n",
       "0  2892106090    False   finalized                   3  12/10/2020 22:54:18   \n",
       "1  2892106091    False   finalized                   3  12/10/2020 22:54:18   \n",
       "2  2892106092    False   finalized                   3  12/10/2020 22:54:18   \n",
       "3  2892106093    False   finalized                   3  12/10/2020 22:54:18   \n",
       "4  2892106094    False   finalized                   3  12/10/2020 22:55:10   \n",
       "\n",
       "  helpfulness  confidence      no  \\\n",
       "0     helpful      1.0000   23768   \n",
       "1     helpful      1.0000  173933   \n",
       "2     helpful      0.6765  213748   \n",
       "3     helpful      1.0000  147649   \n",
       "4     helpful      0.6604   89990   \n",
       "\n",
       "                                              review  \\\n",
       "0  جيد. مديرة خدمة العملاء الانسه بشرى جدا متميزة...   \n",
       "1  مقبول. موقع ممتاز. انتظار الاصنصير طويل لم يكن...   \n",
       "2  جيد. الموقع ، طاقم العمل بشوشين ، مكان الافطار...   \n",
       "3  “ممتازة”. كل شي رائع و نظيف و الاسرة نظيفة ومر...   \n",
       "4  “اروع فندق”. كل شي كان فندق حقيقة اكثر من رائع...   \n",
       "\n",
       "                                           review_en  \n",
       "0  good. Director of Customer Service Miss Bushra...  \n",
       "1  Acceptable. Excellent location. Waiting for a ...  \n",
       "2  good. Location, staff Bchocan, place a small b...  \n",
       "3  \"Excellent\". Everything wonderful and clean an...  \n",
       "4  \"Finest hotel.\" Everything was more than a hot...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hotel_labeled_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "struct..\n",
      "ugr..\n",
      "2784\n",
      "cleaning .. \n",
      "tf-idf .. \n",
      "infrequent words .. \n",
      "scaling words .. \n",
      "galc\n",
      "liwc\n",
      "inq\n"
     ]
    }
   ],
   "source": [
    "extract_all_features(hotel_labeled_data['review_en'],min_doc_freq=3,saveto='hotel_review_features_appen')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "books_labeled_data = pd.read_csv('apen/books/appen_translated - books.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "struct..\n",
      "ugr..\n",
      "2784\n",
      "cleaning .. \n",
      "tf-idf .. \n",
      "infrequent words .. \n",
      "scaling words .. \n",
      "galc\n",
      "liwc\n",
      "inq\n"
     ]
    }
   ],
   "source": [
    "extract_all_features(hotel_labeled_data['review_en'],min_doc_freq=3,saveto='books_review_features_appen')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
