{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import dill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>name</th>\n",
       "      <th>score</th>\n",
       "      <th>helpful</th>\n",
       "      <th>rating</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>book_11014</td>\n",
       "      <td>60.193011</td>\n",
       "      <td>3/7</td>\n",
       "      <td>2</td>\n",
       "      <td>The Plot for The Giver\\n     The plot for the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>book_111659</td>\n",
       "      <td>63.900913</td>\n",
       "      <td>6/8</td>\n",
       "      <td>5</td>\n",
       "      <td>THERE &amp;amp; BACK AGAIN\\n     AWESOME book! Ori...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>book_111922</td>\n",
       "      <td>36.199948</td>\n",
       "      <td>1/16</td>\n",
       "      <td>1</td>\n",
       "      <td>How do you keep an idiot busy for hours?\\n    ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>book_114362</td>\n",
       "      <td>65.307664</td>\n",
       "      <td>2/7</td>\n",
       "      <td>1</td>\n",
       "      <td>Randomness\\n     Did I miss something here? Wh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>book_116528</td>\n",
       "      <td>55.329414</td>\n",
       "      <td>16/45</td>\n",
       "      <td>1</td>\n",
       "      <td>pseudo-intellectual and not interesting\\n     ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0         name      score helpful  rating  \\\n",
       "0           0   book_11014  60.193011     3/7       2   \n",
       "1           1  book_111659  63.900913     6/8       5   \n",
       "2           2  book_111922  36.199948    1/16       1   \n",
       "3           3  book_114362  65.307664     2/7       1   \n",
       "4           4  book_116528  55.329414   16/45       1   \n",
       "\n",
       "                                              review  \n",
       "0  The Plot for The Giver\\n     The plot for the ...  \n",
       "1  THERE &amp; BACK AGAIN\\n     AWESOME book! Ori...  \n",
       "2  How do you keep an idiot busy for hours?\\n    ...  \n",
       "3  Randomness\\n     Did I miss something here? Wh...  \n",
       "4  pseudo-intellectual and not interesting\\n     ...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('books_data.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['review'] = data['review'].apply(lambda x: x.replace('\\n',''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>name</th>\n",
       "      <th>score</th>\n",
       "      <th>helpful</th>\n",
       "      <th>rating</th>\n",
       "      <th>review</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>book_11014</td>\n",
       "      <td>60.193011</td>\n",
       "      <td>3/7</td>\n",
       "      <td>2</td>\n",
       "      <td>The Plot for The Giver     The plot for the bo...</td>\n",
       "      <td>1421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>book_111659</td>\n",
       "      <td>63.900913</td>\n",
       "      <td>6/8</td>\n",
       "      <td>5</td>\n",
       "      <td>THERE &amp;amp; BACK AGAIN     AWESOME book! Origi...</td>\n",
       "      <td>537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>book_111922</td>\n",
       "      <td>36.199948</td>\n",
       "      <td>1/16</td>\n",
       "      <td>1</td>\n",
       "      <td>How do you keep an idiot busy for hours?     I...</td>\n",
       "      <td>375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>book_114362</td>\n",
       "      <td>65.307664</td>\n",
       "      <td>2/7</td>\n",
       "      <td>1</td>\n",
       "      <td>Randomness     Did I miss something here? What...</td>\n",
       "      <td>644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>book_116528</td>\n",
       "      <td>55.329414</td>\n",
       "      <td>16/45</td>\n",
       "      <td>1</td>\n",
       "      <td>pseudo-intellectual and not interesting     At...</td>\n",
       "      <td>502</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0         name      score helpful  rating  \\\n",
       "0           0   book_11014  60.193011     3/7       2   \n",
       "1           1  book_111659  63.900913     6/8       5   \n",
       "2           2  book_111922  36.199948    1/16       1   \n",
       "3           3  book_114362  65.307664     2/7       1   \n",
       "4           4  book_116528  55.329414   16/45       1   \n",
       "\n",
       "                                              review  length  \n",
       "0  The Plot for The Giver     The plot for the bo...    1421  \n",
       "1  THERE &amp; BACK AGAIN     AWESOME book! Origi...     537  \n",
       "2  How do you keep an idiot busy for hours?     I...     375  \n",
       "3  Randomness     Did I miss something here? What...     644  \n",
       "4  pseudo-intellectual and not interesting     At...     502  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['length'] = data.review.apply(lambda x: len(x))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## scale features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['score'] = data['score'].apply(lambda x: x/100);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>name</th>\n",
       "      <th>score</th>\n",
       "      <th>helpful</th>\n",
       "      <th>rating</th>\n",
       "      <th>review</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>book_11014</td>\n",
       "      <td>0.601930</td>\n",
       "      <td>3/7</td>\n",
       "      <td>2</td>\n",
       "      <td>The Plot for The Giver     The plot for the bo...</td>\n",
       "      <td>1421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>book_111659</td>\n",
       "      <td>0.639009</td>\n",
       "      <td>6/8</td>\n",
       "      <td>5</td>\n",
       "      <td>THERE &amp;amp; BACK AGAIN     AWESOME book! Origi...</td>\n",
       "      <td>537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>book_111922</td>\n",
       "      <td>0.361999</td>\n",
       "      <td>1/16</td>\n",
       "      <td>1</td>\n",
       "      <td>How do you keep an idiot busy for hours?     I...</td>\n",
       "      <td>375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>book_114362</td>\n",
       "      <td>0.653077</td>\n",
       "      <td>2/7</td>\n",
       "      <td>1</td>\n",
       "      <td>Randomness     Did I miss something here? What...</td>\n",
       "      <td>644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>book_116528</td>\n",
       "      <td>0.553294</td>\n",
       "      <td>16/45</td>\n",
       "      <td>1</td>\n",
       "      <td>pseudo-intellectual and not interesting     At...</td>\n",
       "      <td>502</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0         name     score helpful  rating  \\\n",
       "0           0   book_11014  0.601930     3/7       2   \n",
       "1           1  book_111659  0.639009     6/8       5   \n",
       "2           2  book_111922  0.361999    1/16       1   \n",
       "3           3  book_114362  0.653077     2/7       1   \n",
       "4           4  book_116528  0.553294   16/45       1   \n",
       "\n",
       "                                              review  length  \n",
       "0  The Plot for The Giver     The plot for the bo...    1421  \n",
       "1  THERE &amp; BACK AGAIN     AWESOME book! Origi...     537  \n",
       "2  How do you keep an idiot busy for hours?     I...     375  \n",
       "3  Randomness     Did I miss something here? What...     644  \n",
       "4  pseudo-intellectual and not interesting     At...     502  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ratio(string):\n",
    "    num1 = int(string[:string.index('/')])\n",
    "    num2 = int(string[string.index('/')+1:])\n",
    "    return num1/num2\n",
    "\n",
    "data.helpful = data.helpful.apply(lambda x: ratio(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>name</th>\n",
       "      <th>score</th>\n",
       "      <th>helpful</th>\n",
       "      <th>rating</th>\n",
       "      <th>review</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>book_11014</td>\n",
       "      <td>0.601930</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>2</td>\n",
       "      <td>The Plot for The Giver     The plot for the bo...</td>\n",
       "      <td>1421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>book_111659</td>\n",
       "      <td>0.639009</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>5</td>\n",
       "      <td>THERE &amp;amp; BACK AGAIN     AWESOME book! Origi...</td>\n",
       "      <td>537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>book_111922</td>\n",
       "      <td>0.361999</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>1</td>\n",
       "      <td>How do you keep an idiot busy for hours?     I...</td>\n",
       "      <td>375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>book_114362</td>\n",
       "      <td>0.653077</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>1</td>\n",
       "      <td>Randomness     Did I miss something here? What...</td>\n",
       "      <td>644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>book_116528</td>\n",
       "      <td>0.553294</td>\n",
       "      <td>0.355556</td>\n",
       "      <td>1</td>\n",
       "      <td>pseudo-intellectual and not interesting     At...</td>\n",
       "      <td>502</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0         name     score   helpful  rating  \\\n",
       "0           0   book_11014  0.601930  0.428571       2   \n",
       "1           1  book_111659  0.639009  0.750000       5   \n",
       "2           2  book_111922  0.361999  0.062500       1   \n",
       "3           3  book_114362  0.653077  0.285714       1   \n",
       "4           4  book_116528  0.553294  0.355556       1   \n",
       "\n",
       "                                              review  length  \n",
       "0  The Plot for The Giver     The plot for the bo...    1421  \n",
       "1  THERE &amp; BACK AGAIN     AWESOME book! Origi...     537  \n",
       "2  How do you keep an idiot busy for hours?     I...     375  \n",
       "3  Randomness     Did I miss something here? What...     644  \n",
       "4  pseudo-intellectual and not interesting     At...     502  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>name</th>\n",
       "      <th>score</th>\n",
       "      <th>helpful</th>\n",
       "      <th>rating</th>\n",
       "      <th>review</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>book_11014</td>\n",
       "      <td>0.601930</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.08</td>\n",
       "      <td>The Plot for The Giver     The plot for the bo...</td>\n",
       "      <td>1421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>book_111659</td>\n",
       "      <td>0.639009</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.20</td>\n",
       "      <td>THERE &amp;amp; BACK AGAIN     AWESOME book! Origi...</td>\n",
       "      <td>537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>book_111922</td>\n",
       "      <td>0.361999</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.04</td>\n",
       "      <td>How do you keep an idiot busy for hours?     I...</td>\n",
       "      <td>375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>book_114362</td>\n",
       "      <td>0.653077</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.04</td>\n",
       "      <td>Randomness     Did I miss something here? What...</td>\n",
       "      <td>644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>book_116528</td>\n",
       "      <td>0.553294</td>\n",
       "      <td>0.355556</td>\n",
       "      <td>0.04</td>\n",
       "      <td>pseudo-intellectual and not interesting     At...</td>\n",
       "      <td>502</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0         name     score   helpful  rating  \\\n",
       "0           0   book_11014  0.601930  0.428571    0.08   \n",
       "1           1  book_111659  0.639009  0.750000    0.20   \n",
       "2           2  book_111922  0.361999  0.062500    0.04   \n",
       "3           3  book_114362  0.653077  0.285714    0.04   \n",
       "4           4  book_116528  0.553294  0.355556    0.04   \n",
       "\n",
       "                                              review  length  \n",
       "0  The Plot for The Giver     The plot for the bo...    1421  \n",
       "1  THERE &amp; BACK AGAIN     AWESOME book! Origi...     537  \n",
       "2  How do you keep an idiot busy for hours?     I...     375  \n",
       "3  Randomness     Did I miss something here? What...     644  \n",
       "4  pseudo-intellectual and not interesting     At...     502  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.rating = data.rating.apply(lambda x: x/5)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>name</th>\n",
       "      <th>score</th>\n",
       "      <th>helpful</th>\n",
       "      <th>rating</th>\n",
       "      <th>review</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>book_11014</td>\n",
       "      <td>0.601930</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.4</td>\n",
       "      <td>The Plot for The Giver     The plot for the bo...</td>\n",
       "      <td>1421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>book_111659</td>\n",
       "      <td>0.639009</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>THERE &amp;amp; BACK AGAIN     AWESOME book! Origi...</td>\n",
       "      <td>537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>book_111922</td>\n",
       "      <td>0.361999</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.2</td>\n",
       "      <td>How do you keep an idiot busy for hours?     I...</td>\n",
       "      <td>375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>book_114362</td>\n",
       "      <td>0.653077</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Randomness     Did I miss something here? What...</td>\n",
       "      <td>644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>book_116528</td>\n",
       "      <td>0.553294</td>\n",
       "      <td>0.355556</td>\n",
       "      <td>0.2</td>\n",
       "      <td>pseudo-intellectual and not interesting     At...</td>\n",
       "      <td>502</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0         name     score   helpful  rating  \\\n",
       "0           0   book_11014  0.601930  0.428571     0.4   \n",
       "1           1  book_111659  0.639009  0.750000     1.0   \n",
       "2           2  book_111922  0.361999  0.062500     0.2   \n",
       "3           3  book_114362  0.653077  0.285714     0.2   \n",
       "4           4  book_116528  0.553294  0.355556     0.2   \n",
       "\n",
       "                                              review  length  \n",
       "0  The Plot for The Giver     The plot for the bo...    1421  \n",
       "1  THERE &amp; BACK AGAIN     AWESOME book! Origi...     537  \n",
       "2  How do you keep an idiot busy for hours?     I...     375  \n",
       "3  Randomness     Did I miss something here? What...     644  \n",
       "4  pseudo-intellectual and not interesting     At...     502  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.rating = data.rating.apply(lambda x: x*5)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Structural "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## total number of tokens, total number of sentences, av- erage length of sentences, number of exclamation marks, and the percentage of question sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_structural(reviews):\n",
    "    \n",
    "    #initiate dataframe\n",
    "    results = pd.DataFrame(reviews)\n",
    "    results.columns = ['review']\n",
    "    \n",
    "    #extract feats\n",
    "    results['length'] = results.review.apply(lambda x: len(x))\n",
    "    results['num_tokens'] = results.review.apply(lambda x: len(x.split(' ')))\n",
    "    results['num_sentences'] = results.review.apply(lambda x: x.count('.'))\n",
    "    results['avg_sent_len'] = results.review.apply(lambda x: avg_sent_length(x))\n",
    "    results['num_exclm_mark'] = results.review.apply(lambda x: x.count('!'))\n",
    "    results['ratio_q'] = results.review.apply(lambda x: per_of_q(x))\n",
    "    \n",
    "    #save file\n",
    "    results.to_csv('struct_feats.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test\n",
    "a = ['hloow omar.','i like this thing','no no no','what?']\n",
    "extract_structural(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>name</th>\n",
       "      <th>score</th>\n",
       "      <th>helpful</th>\n",
       "      <th>rating</th>\n",
       "      <th>review</th>\n",
       "      <th>length</th>\n",
       "      <th>num_sentences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>book_11014</td>\n",
       "      <td>60.193011</td>\n",
       "      <td>3/7</td>\n",
       "      <td>2</td>\n",
       "      <td>The Plot for The Giver     The plot for the bo...</td>\n",
       "      <td>1421</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>book_111659</td>\n",
       "      <td>63.900913</td>\n",
       "      <td>6/8</td>\n",
       "      <td>5</td>\n",
       "      <td>THERE &amp;amp; BACK AGAIN     AWESOME book! Origi...</td>\n",
       "      <td>537</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>book_111922</td>\n",
       "      <td>36.199948</td>\n",
       "      <td>1/16</td>\n",
       "      <td>1</td>\n",
       "      <td>How do you keep an idiot busy for hours?     I...</td>\n",
       "      <td>375</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>book_114362</td>\n",
       "      <td>65.307664</td>\n",
       "      <td>2/7</td>\n",
       "      <td>1</td>\n",
       "      <td>Randomness     Did I miss something here? What...</td>\n",
       "      <td>644</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>book_116528</td>\n",
       "      <td>55.329414</td>\n",
       "      <td>16/45</td>\n",
       "      <td>1</td>\n",
       "      <td>pseudo-intellectual and not interesting     At...</td>\n",
       "      <td>502</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0         name      score helpful  rating  \\\n",
       "0           0   book_11014  60.193011     3/7       2   \n",
       "1           1  book_111659  63.900913     6/8       5   \n",
       "2           2  book_111922  36.199948    1/16       1   \n",
       "3           3  book_114362  65.307664     2/7       1   \n",
       "4           4  book_116528  55.329414   16/45       1   \n",
       "\n",
       "                                              review  length  num_sentences  \n",
       "0  The Plot for The Giver     The plot for the bo...    1421             16  \n",
       "1  THERE &amp; BACK AGAIN     AWESOME book! Origi...     537             10  \n",
       "2  How do you keep an idiot busy for hours?     I...     375              4  \n",
       "3  Randomness     Did I miss something here? What...     644              5  \n",
       "4  pseudo-intellectual and not interesting     At...     502              7  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# totla number of sentences \n",
    "\n",
    "data['num_sentences'] = data.review.apply(lambda x: x.count('.'))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>name</th>\n",
       "      <th>score</th>\n",
       "      <th>helpful</th>\n",
       "      <th>rating</th>\n",
       "      <th>review</th>\n",
       "      <th>length</th>\n",
       "      <th>num_sentences</th>\n",
       "      <th>avg_sent_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>book_11014</td>\n",
       "      <td>60.193011</td>\n",
       "      <td>3/7</td>\n",
       "      <td>2</td>\n",
       "      <td>The Plot for The Giver     The plot for the bo...</td>\n",
       "      <td>1421</td>\n",
       "      <td>16</td>\n",
       "      <td>82.647059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>book_111659</td>\n",
       "      <td>63.900913</td>\n",
       "      <td>6/8</td>\n",
       "      <td>5</td>\n",
       "      <td>THERE &amp;amp; BACK AGAIN     AWESOME book! Origi...</td>\n",
       "      <td>537</td>\n",
       "      <td>10</td>\n",
       "      <td>47.909091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>book_111922</td>\n",
       "      <td>36.199948</td>\n",
       "      <td>1/16</td>\n",
       "      <td>1</td>\n",
       "      <td>How do you keep an idiot busy for hours?     I...</td>\n",
       "      <td>375</td>\n",
       "      <td>4</td>\n",
       "      <td>74.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>book_114362</td>\n",
       "      <td>65.307664</td>\n",
       "      <td>2/7</td>\n",
       "      <td>1</td>\n",
       "      <td>Randomness     Did I miss something here? What...</td>\n",
       "      <td>644</td>\n",
       "      <td>5</td>\n",
       "      <td>106.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>book_116528</td>\n",
       "      <td>55.329414</td>\n",
       "      <td>16/45</td>\n",
       "      <td>1</td>\n",
       "      <td>pseudo-intellectual and not interesting     At...</td>\n",
       "      <td>502</td>\n",
       "      <td>7</td>\n",
       "      <td>61.875000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0         name      score helpful  rating  \\\n",
       "0           0   book_11014  60.193011     3/7       2   \n",
       "1           1  book_111659  63.900913     6/8       5   \n",
       "2           2  book_111922  36.199948    1/16       1   \n",
       "3           3  book_114362  65.307664     2/7       1   \n",
       "4           4  book_116528  55.329414   16/45       1   \n",
       "\n",
       "                                              review  length  num_sentences  \\\n",
       "0  The Plot for The Giver     The plot for the bo...    1421             16   \n",
       "1  THERE &amp; BACK AGAIN     AWESOME book! Origi...     537             10   \n",
       "2  How do you keep an idiot busy for hours?     I...     375              4   \n",
       "3  Randomness     Did I miss something here? What...     644              5   \n",
       "4  pseudo-intellectual and not interesting     At...     502              7   \n",
       "\n",
       "   avg_sent_len  \n",
       "0     82.647059  \n",
       "1     47.909091  \n",
       "2     74.200000  \n",
       "3    106.500000  \n",
       "4     61.875000  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#average length of sentences\n",
    "\n",
    "def avg_sent_length(string):\n",
    "    sentences = string.split('.')\n",
    "    sum_len = 0\n",
    "    for s in sentences:\n",
    "        sum_len += len(s)\n",
    "    return sum_len/len(sentences)\n",
    "\n",
    "data['avg_sent_len'] = data.review.apply(lambda x: avg_sent_length(x))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>name</th>\n",
       "      <th>score</th>\n",
       "      <th>helpful</th>\n",
       "      <th>rating</th>\n",
       "      <th>review</th>\n",
       "      <th>length</th>\n",
       "      <th>num_sentences</th>\n",
       "      <th>avg_sent_len</th>\n",
       "      <th>num_exclm_mark</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>book_11014</td>\n",
       "      <td>60.193011</td>\n",
       "      <td>3/7</td>\n",
       "      <td>2</td>\n",
       "      <td>The Plot for The Giver     The plot for the bo...</td>\n",
       "      <td>1421</td>\n",
       "      <td>16</td>\n",
       "      <td>82.647059</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>book_111659</td>\n",
       "      <td>63.900913</td>\n",
       "      <td>6/8</td>\n",
       "      <td>5</td>\n",
       "      <td>THERE &amp;amp; BACK AGAIN     AWESOME book! Origi...</td>\n",
       "      <td>537</td>\n",
       "      <td>10</td>\n",
       "      <td>47.909091</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>book_111922</td>\n",
       "      <td>36.199948</td>\n",
       "      <td>1/16</td>\n",
       "      <td>1</td>\n",
       "      <td>How do you keep an idiot busy for hours?     I...</td>\n",
       "      <td>375</td>\n",
       "      <td>4</td>\n",
       "      <td>74.200000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>book_114362</td>\n",
       "      <td>65.307664</td>\n",
       "      <td>2/7</td>\n",
       "      <td>1</td>\n",
       "      <td>Randomness     Did I miss something here? What...</td>\n",
       "      <td>644</td>\n",
       "      <td>5</td>\n",
       "      <td>106.500000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>book_116528</td>\n",
       "      <td>55.329414</td>\n",
       "      <td>16/45</td>\n",
       "      <td>1</td>\n",
       "      <td>pseudo-intellectual and not interesting     At...</td>\n",
       "      <td>502</td>\n",
       "      <td>7</td>\n",
       "      <td>61.875000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0         name      score helpful  rating  \\\n",
       "0           0   book_11014  60.193011     3/7       2   \n",
       "1           1  book_111659  63.900913     6/8       5   \n",
       "2           2  book_111922  36.199948    1/16       1   \n",
       "3           3  book_114362  65.307664     2/7       1   \n",
       "4           4  book_116528  55.329414   16/45       1   \n",
       "\n",
       "                                              review  length  num_sentences  \\\n",
       "0  The Plot for The Giver     The plot for the bo...    1421             16   \n",
       "1  THERE &amp; BACK AGAIN     AWESOME book! Origi...     537             10   \n",
       "2  How do you keep an idiot busy for hours?     I...     375              4   \n",
       "3  Randomness     Did I miss something here? What...     644              5   \n",
       "4  pseudo-intellectual and not interesting     At...     502              7   \n",
       "\n",
       "   avg_sent_len  num_exclm_mark  \n",
       "0     82.647059               1  \n",
       "1     47.909091               1  \n",
       "2     74.200000               0  \n",
       "3    106.500000               0  \n",
       "4     61.875000               0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# num of excalmation marks\n",
    "\n",
    "data['num_exclm_mark'] = data.review.apply(lambda x: x.count('!'))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# % of question sentences ( I will only consider the ? mark now and later can change it)\n",
    "\n",
    "def per_of_q(string):\n",
    "    \n",
    "    num_q = string.count(\"?\")\n",
    "    new_string = string.replace(\"?\",\".\")\n",
    "    sentences = new_string.split(\".\")\n",
    "    \n",
    "    return num_q/len(sentences)\n",
    "    \n",
    "data['ratio_q'] = data.review.apply(lambda x: per_of_q(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>name</th>\n",
       "      <th>score</th>\n",
       "      <th>helpful</th>\n",
       "      <th>rating</th>\n",
       "      <th>review</th>\n",
       "      <th>length</th>\n",
       "      <th>num_sentences</th>\n",
       "      <th>avg_sent_len</th>\n",
       "      <th>num_exclm_mark</th>\n",
       "      <th>ratio_q</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>book_11014</td>\n",
       "      <td>0.601930</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.4</td>\n",
       "      <td>The Plot for The Giver     The plot for the bo...</td>\n",
       "      <td>1421</td>\n",
       "      <td>16</td>\n",
       "      <td>82.647059</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>book_111659</td>\n",
       "      <td>0.639009</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>THERE &amp;amp; BACK AGAIN     AWESOME book! Origi...</td>\n",
       "      <td>537</td>\n",
       "      <td>10</td>\n",
       "      <td>47.909091</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>book_111922</td>\n",
       "      <td>0.361999</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.2</td>\n",
       "      <td>How do you keep an idiot busy for hours?     I...</td>\n",
       "      <td>375</td>\n",
       "      <td>4</td>\n",
       "      <td>74.200000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>book_114362</td>\n",
       "      <td>0.653077</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Randomness     Did I miss something here? What...</td>\n",
       "      <td>644</td>\n",
       "      <td>5</td>\n",
       "      <td>106.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>book_116528</td>\n",
       "      <td>0.553294</td>\n",
       "      <td>0.355556</td>\n",
       "      <td>0.2</td>\n",
       "      <td>pseudo-intellectual and not interesting     At...</td>\n",
       "      <td>502</td>\n",
       "      <td>7</td>\n",
       "      <td>61.875000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0         name     score   helpful  rating  \\\n",
       "0           0   book_11014  0.601930  0.428571     0.4   \n",
       "1           1  book_111659  0.639009  0.750000     1.0   \n",
       "2           2  book_111922  0.361999  0.062500     0.2   \n",
       "3           3  book_114362  0.653077  0.285714     0.2   \n",
       "4           4  book_116528  0.553294  0.355556     0.2   \n",
       "\n",
       "                                              review  length  num_sentences  \\\n",
       "0  The Plot for The Giver     The plot for the bo...    1421             16   \n",
       "1  THERE &amp; BACK AGAIN     AWESOME book! Origi...     537             10   \n",
       "2  How do you keep an idiot busy for hours?     I...     375              4   \n",
       "3  Randomness     Did I miss something here? What...     644              5   \n",
       "4  pseudo-intellectual and not interesting     At...     502              7   \n",
       "\n",
       "   avg_sent_len  num_exclm_mark   ratio_q  \n",
       "0     82.647059               1  0.000000  \n",
       "1     47.909091               1  0.000000  \n",
       "2     74.200000               0  0.166667  \n",
       "3    106.500000               0  0.333333  \n",
       "4     61.875000               0  0.000000  "
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# URG (TF-IDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ugr(reviews,min_doc_freq=0):\n",
    "    from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "    from nltk.corpus import stopwords\n",
    "\n",
    "    #remove stop_words \n",
    "    reviews_clean = []\n",
    "    stop_words = stopwords.words('english');\n",
    "    stop_words += [\"the\",\"and\",\"it\"]\n",
    "\n",
    "    for r in reviews:\n",
    "        clean_r = r\n",
    "        for w in r.split(' '):\n",
    "            if w in stop_words: \n",
    "                clean_r = clean_r.replace(w,\"\");\n",
    "        reviews_clean.append(clean_r)\n",
    "\n",
    "    # calculate tf-idf\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    vectors = vectorizer.fit_transform(reviews_clean)\n",
    "    feature_names = vectorizer.get_feature_names()\n",
    "    dense = vectors.todense()\n",
    "    denselist = dense.tolist()\n",
    "\n",
    "    tf_idf = pd.DataFrame(denselist, columns=feature_names)\n",
    "\n",
    "    #remove infrequent words\n",
    "    cols = []\n",
    "    for c in tf_idf.columns:\n",
    "        col = tf_idf[c]\n",
    "        num_non_zer = 0\n",
    "        for r in col:\n",
    "            if r != 0:\n",
    "                num_non_zer += 1\n",
    "        if num_non_zer < min_doc_freq:\n",
    "            cols.append(c)\n",
    "    tf_idf_freq = tf_idf.drop(columns=cols)\n",
    "    \n",
    "    #save file\n",
    "    tf_idf_freq.to_csv('results/tf_idf_freq.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = ['hloow omar.','i like this thing','no no no','what?']\n",
    "ugr(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3580\n",
      "3580\n",
      "867\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dict_keys(['', 'who', '(or', 'old', 'race', 'characters', 'reviewers', 'rise', 'all,', 'amazing', 'character', 'makes', 'soon', 'best', 'due', 'where', 'things', 'com', 'version', 'described', 'He', 'exact', 'create', 'core', 'real', 'end,', 'How', 'novel.', 'regardless', 'train', 'somewhat', 'cover', 'forced', \"Rand's\", 'way', 'than', 'those', 'hours', \"won't\", 'king', 'will', 'answer', 'she', 'stuff', 'sitting', 'finally', 'powerful', 'takes', 'im', 'religious', 'an', 'books', 'before', 'life.', 'perfect', 'drive', '-', 'teenager', 'Although', 'care', 'school', 'while', 'opinion', 'ages', 'America', 'boy', 'little', 'instead', 'rough', 'level', 'ties', 'stop', 'try', 'around', 'attention', 'always', 'we', 'read,', 'seller', 'simply', 'am', 'or', 'in', 'personal', 'having', 'Or', 'For', 'plot.', 'consider', 'arguments', \"that's\", 'between', 'And', 'finish', 'In', 'become', 'like', 'written', 'sure', 'truth', 'Great', 'class', 'it,', 'fortune', 'style', 'return', 'men', 'ready', 'impress', 'recent', 'think', 'example', 'friend', 'page', 'Maybe', 'times', 'guess', 'conservative', 'sound', 'been', 'even', 'author', 'reading', 'ends', 'which', 'tea', 'seem', 'dwarves', 'back', 'ages.', 'work', 'thin', 'able', 'age', 'stories', 'epic', 'done', 'look', 'NOT', 'shows', 'literature', 'early', 'references', 'moral', 'time.', 'wing', 'second', 'mean', 'me', 'land', 'pain', 'year', 'teens', 'book.', 'rest', 'day', 'reads', 'fact', 'start', 'is.', 'making', 'sent', 'right', 'My', 'sea', 'Man', 'late', 'home', 'for', 'clear', 'There', 'maybe', 'current', 'clearly', 'your', 'listed', 'Thank', 'format', 'everyone', 'them.', 'are', 'why', 'crap', 'number', 'seek', 'An', 'premise', '--', 'how', 'too', 'son', 'murder', 'boring', 'book!', 'expect', 'feel', 'book,', 'historical', 'any', 'cult', 'sense', 'ill', 'logic', 'follow', 'anything', 'go', 'aged', 'their', 'student', 'word', 'rave', 'movie', 'country', 'Vinci', 'era', 'could', 'bit', 'deep', 'bad', 'social', 'claim', \"doesn't\", 'search', '15', 'yes', \"isn't\", 'ado', 'Jonas', 'role', 'lame', 'product', '.', 'my', 'His', 'difference', 'earn', 'last', 'day.', 'philosophical', 'love', '20', 'line', 'copy', 'about', 'lazy', 'have', '...', 'market', 'ON', 'die', 'toward', 'people', 'miss', 'run', 'if', 'definitely', 'again', 'over', 'lives', 'Best', 'paperback', 'not', 'worth', 'beautiful', 'made', 'past', 'that.', 'other', 'hit', 'standard', 'starts', 'count', 'usually', 'felt', 'action', 'free', 'Smaug', 'highly', 'its', 'We', 'leave', 'course', 'few', 'silly', 'day,', 'presented', 'fell', 'Christianity', 'rant', 'That', 'tried', 'nice', 'helpful', 'The', 'such', 'On', 'aimed', 'disappointed', 'Of', 'both', 'But', 'child', 'A', 'Amazon.', 'Give', 'fantasy', 'One', 'evil', 'paper', 'brings', 'broke', 'While', 'him', 'going', 'on', 'else', 'poor', 'sit', '200', 'completely', 'tell', 'lists', 'short', 'and,', 'imagine', 'spite', 'quite', 'busy', 'once', 'society.', 'pages,', 'readers', 'give', 'still', 'disappointing', 'piece', 'month', 'years', 'Dagny', 'similar', 'cut', 'one.', 'enjoy', 'minded', 'dry', 'difficult', 'though', 'found', 'today', 'would', 'it.', 'that', 'these', 'important', 'NOVEL', '(in', 'air', 'well', 'problems', 'especially', 'you,', 'previous', 'said', 'plot', 'Ayn', 'every', 'live', 'wonderful', 'take', 'down', 'several', 'now', 'story', 'up', 'quest', 'Baggins', 'stars', \"it's\", 'change', 'issue', 'ways', 'history', 'accurate', \"I'm\", 'Hobbit.', 'understanding', 'under', 'out.', 'loved', 'Too', 'find', 'power', 'kind', 'high', 'each', 'need', 'story,', 'se,', 'help', 'recommended', 'recommend', 'political', 'ought', 'has', 'his', \"It's\", 'went', 'during', 'Al', 'come', 'want', 'novel', 'novel,', 'also', 'Even', 'see', 'from', 'tead', 'Kerry', 'show', '10', \"you'll\", 'father', 'significant', 'pay', 'prove', 'oft', \"Don't\", 'of', 'since', 'were', \"wasn't\", 'rational', 'philosophy', 'classic', 'They', 'rather', 'a', 'main', 'per', 'dragon', 'capitalism', 'everything', 'sex', 'long', 'make', 'yourself', 'life', 'new', '&', 'ad', '1', 'art', 'You', 'by', 'keep', 'world', 'relationship', 'f', 'what', 'write', 'above', 'days', 'down.', 'information', 'pointed', 'Am', 'pass', 'poorly', 'point', 'hate', 'changed', 'lie', 'When', 'should', 'just', 'true', 'good', 'eight', 'chapter', 'Fountainhead', 'Dan', 'man', 'It', 'So', 'Bilbo', 'review', 'theories', 'writer', 'question', 'game', \"can't\", 'media', 'end.', 'must', 'type', 'exactly', 'government', 'time', 'till', 'idea', 'profound', 'evidence', 'parts', 'called', 'I', 'cannot', 'uses', 'wish', 'occasion', 'adult', 'comes', 'J', 'interesting.', 'writing,', 'principles', 'filled', 'disagree', 'turned', 'anyone', 'another', 'so', 'same', 'inside', 'Brown', 'anything.', 'complain', 'children', 'came', 'sat', '8', 'say', 'disturbing', 'lead', 'very', 'story.', 'cause', 'group', 'read.', 'develop', 'into', 'resort', 'serious', 'value', 'recently', 'put', 'receive', 'After', 'complete', 'waste', 'off', 'ensure', 'view', 'However,', 'drawn', 'careful', 'know', 'abridged', '50', 'Shrugged', 'six', 'historic', 'away.', 'Amazon', 'reason', 'b', 'struggle', 'being', 'through', 'most', 'serve', 'let', 'parent', 'net', 'the', 'young', 'without', 'Da', 'do', 'ideas', 'because', 'interesting', 'named', 'bored', 'Hobbit', 'her', 'reading.', 'etc.', 'mind,', 'does', 'can', 'probably', 'form', 'ever', 'whole', 'but', 'believe', 'person', 'times,', 'speech', 'sue', 'lot', 'enough', 'fun', 'adventure', 'fall', 'owing', 'you', 'mix', '6', 'self', \"Holden's\", 'hard', 'rating', 'when', 'All', 'grand', 'led', 'earlier', 'says', 'drawings', 'customer', 'only', 'society', 'Harry', 'numerous', 'etc', 'mostly', 'given', 'read', 'is,', 'some', 'lay', 'them', 'No', 'certainly', 'really', \"I've\", 'excellent', 'quit', 'sort', 'Yet', 'there', 'series', 'fiction.', 'intelligent', 'Every', 'star', 'excuse', 'be', 'along', 'side', 'New', 'limited', 'himself', 'her,', 'crafted', 'print', 'fictional', 'themselves', 'they', 'John', 'weak', 'then', 'notes', 'mother', 'stupid', 'This', 'xi', 'reference', 'begin', 'fill', 'often', 'away', 'i', 'elves.', 'Some', 'writing', 'out', 'hold', 'reader', 'To', 'totally', 'If', 'here,', 'gift', 'owe', 'At', 'never', 'save', 'hear', 'me.', 'including', 'Be', 'fiction', 'on,', 'go.', 'content', 'lying', 'edition', 'was', 'interested', 'beginning', 'great', '3', 'gets', 'publishing', 'description', 'either', 'all', 'asleep', 'may', 'mind', 'five', 'coming', 'Holden', 'full', 'certain', 'characters,', 'works', 'Do', 'human', 'own', 'part', 'list', 'What', 'acts', 'published', 'get', 'lied', \"didn't\", 'way,', '\"The', \"today's\", 'supposed', 'understand', 'many', 's', 'getting', 'storyline', 'suggest', 'x', 'hobbit', \"book's\", 'da', 'Read', 'worst', 'better', 'no', 'here', 'Mr.', 'picture', 'actual', 'hi', 'appear', 'As', 'happened', 'nothing', 'note', 'bet', 'illustrations', 'might', 'longer', 'end', 'fine', 'Bush', 'reviews', 'accept', 'today.', 'it', 'conspiracy', 'tale', 'result', 'text', 'BACK', 'time,', 'got', 'support', 'thing.', 'wrote', 'more', 'Not', 'one', 'open', '(I', 'modern', 'instead.', 'truth,', 'to.', 'world.', 'wants', 'agree', 'issues', 'thought', 'had', 'quality', 'light', 'considered', 'on.', 'least', 'wonder', 'call', 'ending', 'except', 'two', 'much', 'he', 'as', 'our', 'written,', 'treasure', 'research', 'friends', 'please', 'rely', 'special', 'book', 'included', 'Most', 'questions', 'Rand', 'reality', 'Much', 'first', 'Tolkien', 'less', 'teenage', 'deal', 'slow', 'well,', 'ship', 'taken', 'exist.', 'contact', 'ask', 'this', 'is', 'mass', 'with', 'heard', 'to', \"don't\", 'teen', 'danger', 'actually', 'something', 'American', 'and', 'however,', 'belief', '4', 'far', 'point.', 'ok', 'Atlas', 'did', 'storyline.', 'Yes,', 'at', 'thing', 'close', 'argument', 'pages', 'after', 'words', 'choice', 'use'])"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#calc infrequent words\n",
    "\n",
    "bow = []\n",
    "for r in data.review:\n",
    "    bow += r.split(' ')\n",
    "bow = set(bow)\n",
    "print(len(bow))\n",
    "\n",
    "words_n = dict.fromkeys(bow,0)\n",
    "print(len(words_n))\n",
    "\n",
    "for w in bow:\n",
    "    for r in data.review:\n",
    "        if w in r:\n",
    "            words_n[w] += 1\n",
    "\n",
    "bow_freq = {k:v for k,v in words_n.items() if v > 2}\n",
    "print(len(bow_freq))\n",
    "\n",
    "bow_freq.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>000</th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>1000</th>\n",
       "      <th>105</th>\n",
       "      <th>12</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>...</th>\n",
       "      <th>young</th>\n",
       "      <th>younger</th>\n",
       "      <th>yourself</th>\n",
       "      <th>youth</th>\n",
       "      <th>yself</th>\n",
       "      <th>ythg</th>\n",
       "      <th>yugoslvi</th>\n",
       "      <th>yuk</th>\n",
       "      <th>zero</th>\n",
       "      <th>zgly</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.076801</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.178732</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2770 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   000   10  100      1000  105        12   14   15   16   17  ...  young  \\\n",
       "0  0.0  0.0  0.0  0.000000  0.0  0.076801  0.0  0.0  0.0  0.0  ...    0.0   \n",
       "1  0.0  0.0  0.0  0.000000  0.0  0.000000  0.0  0.0  0.0  0.0  ...    0.0   \n",
       "2  0.0  0.0  0.0  0.000000  0.0  0.000000  0.0  0.0  0.0  0.0  ...    0.0   \n",
       "3  0.0  0.0  0.0  0.000000  0.0  0.000000  0.0  0.0  0.0  0.0  ...    0.0   \n",
       "4  0.0  0.0  0.0  0.178732  0.0  0.000000  0.0  0.0  0.0  0.0  ...    0.0   \n",
       "\n",
       "   younger  yourself  youth  yself  ythg  yugoslvi  yuk  zero  zgly  \n",
       "0      0.0       0.0    0.0    0.0   0.0       0.0  0.0   0.0   0.0  \n",
       "1      0.0       0.0    0.0    0.0   0.0       0.0  0.0   0.0   0.0  \n",
       "2      0.0       0.0    0.0    0.0   0.0       0.0  0.0   0.0   0.0  \n",
       "3      0.0       0.0    0.0    0.0   0.0       0.0  0.0   0.0   0.0  \n",
       "4      0.0       0.0    0.0    0.0   0.0       0.0  0.0   0.0   0.0  \n",
       "\n",
       "[5 rows x 2770 columns]"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TF-IDF (I only removed words from nltk and \"the\" >> Remove more words and infrequent words)\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "#remove stop_words \n",
    "reviews_clean = []\n",
    "stop_words = stopwords.words('english');\n",
    "stop_words += [\"the\",\"and\",\"it\"]\n",
    "\n",
    "for r in data.review:\n",
    "    clean_r = r\n",
    "    for w in r.split(' '):\n",
    "        if w in stop_words: \n",
    "            clean_r = clean_r.replace(w,\"\");\n",
    "    reviews_clean.append(clean_r)\n",
    "    \n",
    "            \n",
    "# calculate tf-idf\n",
    "vectorizer = TfidfVectorizer()\n",
    "vectors = vectorizer.fit_transform(reviews_clean)\n",
    "feature_names = vectorizer.get_feature_names()\n",
    "dense = vectors.todense()\n",
    "denselist = dense.tolist()\n",
    "\n",
    "tf_idf = pd.DataFrame(denselist, columns=feature_names)\n",
    "\n",
    "#remove infrequent words\n",
    "\n",
    "tf_idf.to_csv(\"tf-idf.csv\")\n",
    "tf_idf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove infrequent words\n",
    "cols = []\n",
    "for c in tf_idf.columns:\n",
    "    col = tf_idf[c]\n",
    "    num_non_zer = 0\n",
    "    for r in col:\n",
    "        if r != 0:\n",
    "            num_non_zer += 1\n",
    "    if num_non_zer < 3:\n",
    "        cols.append(c)\n",
    "tf_idf_freq = tf_idf.drop(columns=cols)\n",
    "tf_idf_freq.to_csv('tf_idf_freq.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>15</th>\n",
       "      <th>200</th>\n",
       "      <th>50</th>\n",
       "      <th>after</th>\n",
       "      <th>al</th>\n",
       "      <th>all</th>\n",
       "      <th>although</th>\n",
       "      <th>americ</th>\n",
       "      <th>amzon</th>\n",
       "      <th>and</th>\n",
       "      <th>...</th>\n",
       "      <th>wrten</th>\n",
       "      <th>ws</th>\n",
       "      <th>wsn</th>\n",
       "      <th>wt</th>\n",
       "      <th>wy</th>\n",
       "      <th>yer</th>\n",
       "      <th>yers</th>\n",
       "      <th>yes</th>\n",
       "      <th>yet</th>\n",
       "      <th>you</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.064962</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.109108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 462 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    15  200   50  after   al       all  although  americ  amzon  and  ...  \\\n",
       "0  0.0  0.0  0.0    0.0  0.0  0.064962       0.0     0.0    0.0  0.0  ...   \n",
       "1  0.0  0.0  0.0    0.0  0.0  0.000000       0.0     0.0    0.0  0.0  ...   \n",
       "2  0.0  0.0  0.0    0.0  0.0  0.000000       0.0     0.0    0.0  0.0  ...   \n",
       "3  0.0  0.0  0.0    0.0  0.0  0.000000       0.0     0.0    0.0  0.0  ...   \n",
       "4  0.0  0.0  0.0    0.0  0.0  0.000000       0.0     0.0    0.0  0.0  ...   \n",
       "\n",
       "   wrten   ws  wsn   wt   wy  yer  yers  yes  yet       you  \n",
       "0    0.0  0.0  0.0  0.0  0.0  0.0   0.0  0.0  0.0  0.000000  \n",
       "1    0.0  0.0  0.0  0.0  0.0  0.0   0.0  0.0  0.0  0.000000  \n",
       "2    0.0  0.0  0.0  0.0  0.0  0.0   0.0  0.0  0.0  0.000000  \n",
       "3    0.0  0.0  0.0  0.0  0.0  0.0   0.0  0.0  0.0  0.109108  \n",
       "4    0.0  0.0  0.0  0.0  0.0  0.0   0.0  0.0  0.0  0.000000  \n",
       "\n",
       "[5 rows x 462 columns]"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idf_freq.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# GALC "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [],
   "source": [
    "def galc(reviews):\n",
    "    \n",
    "    # read galc dictionary\n",
    "    with open('galc_dict.json') as json_file:\n",
    "        galc_dict = json.load(json_file)\n",
    "    \n",
    "    #init dataframe\n",
    "    galc_feature = pd.DataFrame(np.zeros((len(data),len(galc_dict))))\n",
    "    galc_feature.columns = list(galc_dict.keys())\n",
    "\n",
    "    def galc_vector_feature(review):\n",
    "        ps = PorterStemmer()\n",
    "        dic = dict.fromkeys(galc_dict.keys(),0)\n",
    "\n",
    "        for w in review.split(' '):\n",
    "            word = w.replace('.','')\n",
    "            stemmed = ps.stem(word)\n",
    "\n",
    "            for categ,words in galc_dict.items():\n",
    "                if stemmed in words:\n",
    "                    dic[categ] += 1\n",
    "\n",
    "        return dic.values()\n",
    "\n",
    "    for i,r in galc_feature.iterrows():\n",
    "        galc_feature.iloc[i] = galc_vector_feature(data.iloc[i]['review'])\n",
    "\n",
    "    #Save file\n",
    "    galc_feature.to_csv('results/GALC_Features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [],
   "source": [
    "galc(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# create the galc words dictionary\n",
    "galc_words = pd.read_csv('galc_words.csv')\n",
    "galc_dict = {}\n",
    "temp_dict = {}\n",
    "\n",
    "for i,r in galc_words.iterrows():\n",
    "    galc_dict[r[0].strip()] = r[1].split(', ')\n",
    "\n",
    "for k,v in galc_dict.items():\n",
    "    temp_dict[k] = []\n",
    "    for w in v:\n",
    "        temp_dict[k].append(w.replace('*',''))\n",
    "        \n",
    "galc_dict = temp_dict\n",
    "\n",
    "#save to json\n",
    "import json       \n",
    "with open(\"galc_dict.json\", \"w\") as outfile:  \n",
    "    json.dump(galc_dict, outfile) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "#build the feature vector \n",
    "#(for each occurence of the word/stem we will increase the number of occurence for each category)\n",
    "\n",
    "import numpy as np\n",
    "from nltk.stem import PorterStemmer \n",
    "\n",
    "galc_feature = pd.DataFrame(np.zeros((len(data),len(galc_dict))))\n",
    "galc_feature.columns = list(galc_dict.keys())\n",
    "\n",
    "def galc_vector_feature(review):\n",
    "    ps = PorterStemmer()\n",
    "    dic = dict.fromkeys(galc_dict.keys(),0)\n",
    "\n",
    "    for w in review.split(' '):\n",
    "        word = w.replace('.','')\n",
    "        stemmed = ps.stem(word)\n",
    "        \n",
    "        for categ,words in galc_dict.items():\n",
    "            if stemmed in words:\n",
    "                dic[categ] += 1\n",
    "                \n",
    "    return dic.values()\n",
    "\n",
    "for i,r in galc_feature.iterrows():\n",
    "    galc_feature.iloc[i] = galc_vector_feature(data.iloc[i]['review'])\n",
    "\n",
    "galc_feature.to_csv('GALC_Features.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LIWC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [],
   "source": [
    "def liwc_extract(reviews):\n",
    "    parse, category_names = liwc.load_token_parser('LIWC2007_English100131.dic')\n",
    "\n",
    "    # define helpers\n",
    "    def tokenize(text):\n",
    "        # you may want to use a smarter tokenizer\n",
    "        for match in re.finditer(r'\\w+', text, re.UNICODE):\n",
    "            yield match.group(0)\n",
    "\n",
    "    def liwc_features(text):\n",
    "\n",
    "        dic = dict.fromkeys(category_names,0)\n",
    "\n",
    "        gettysburg_tokens = tokenize(text)\n",
    "        gettysburg_counts = Counter(category for token in gettysburg_tokens for category in parse(token))\n",
    "\n",
    "        for k,v in gettysburg_counts.items():\n",
    "            dic[k] = v\n",
    "\n",
    "        return dic.values()\n",
    "    \n",
    "    # init dataframe\n",
    "    liwc_feature = pd.DataFrame(np.zeros((len(reviews),len(category_names))))\n",
    "    liwc_feature.columns = category_names\n",
    "    \n",
    "    #extract feats\n",
    "    for i,r in liwc_feature.iterrows():\n",
    "        liwc_feature.iloc[i] = liwc_features(reviews[i])\n",
    "\n",
    "    #save file\n",
    "    liwc_feature.to_csv('results/LIWC_Features.csv')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = ['hloow omar.','i like this thing','no no no','what?']\n",
    "liwc_extract(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [],
   "source": [
    "import liwc\n",
    "parse, category_names = liwc.load_token_parser('LIWC2007_English100131.dic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "def tokenize(text):\n",
    "    # you may want to use a smarter tokenizer\n",
    "    for match in re.finditer(r'\\w+', text, re.UNICODE):\n",
    "        yield match.group(0)\n",
    "\n",
    "def liwc_features(text):\n",
    "        \n",
    "    dic = dict.fromkeys(category_names,0)\n",
    "    \n",
    "    gettysburg_tokens = tokenize(text)\n",
    "    gettysburg_counts = Counter(category for token in gettysburg_tokens for category in parse(token))\n",
    "    \n",
    "    for k,v in gettysburg_counts.items():\n",
    "        dic[k] = v\n",
    "    \n",
    "    return dic.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "liwc_feature = pd.DataFrame(np.zeros((len(data),len(category_names))))\n",
    "liwc_feature.columns = category_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,r in liwc_feature.iterrows():\n",
    "    liwc_feature.iloc[i] = liwc_features(data.iloc[i]['review'])\n",
    "\n",
    "liwc_feature.to_csv('LIWC_Features.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INQUIRER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inq_extract(reviews):\n",
    "    \n",
    "    #read inq\n",
    "    inq = pd.read_excel('inquirerbasic.xls')\n",
    "    inq_categs = list(inq.columns)\n",
    "    \n",
    "    #init dataframe\n",
    "    inq_features = np.zeros((1,len(inq_categs)),dtype=int)\n",
    "\n",
    "    #extract features \n",
    "    for review in reviews:\n",
    "        inq_feat = dict.fromkeys(inq_categs,0)\n",
    "        for w in review.split(' '):\n",
    "            clean = w.strip().replace('.',\"\").replace(\"?\",'').replace(\",\",\"\").replace(\";\",'').upper()\n",
    "            # if the word exists in the dictionary\n",
    "            if len(inq[inq['Entry'] == clean]) > 0:\n",
    "                row = inq[inq['Entry']==clean].to_dict()\n",
    "                for k,v in row.items():\n",
    "                    vv = list(v.values())[0]\n",
    "                    if isinstance(vv,str):\n",
    "                        inq_feat[k] += 1\n",
    "\n",
    "        # convert the dict to one row features \n",
    "        inq_feat_row = np.array(list(inq_feat.values()),dtype=int).reshape((1,len(inq_categs)))\n",
    "\n",
    "        #combine with big matrix\n",
    "        inq_features = np.concatenate((inq_features,inq_feat_row),axis=0)\n",
    "        \n",
    "    \n",
    "    # save file\n",
    "    inq_features = pd.DataFrame(inq_features)\n",
    "    inq_features.to_csv('results/inq_features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [],
   "source": [
    "inq_extract(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Entry</th>\n",
       "      <th>Source</th>\n",
       "      <th>Positiv</th>\n",
       "      <th>Negativ</th>\n",
       "      <th>Pstv</th>\n",
       "      <th>Affil</th>\n",
       "      <th>Ngtv</th>\n",
       "      <th>Hostile</th>\n",
       "      <th>Strong</th>\n",
       "      <th>Power</th>\n",
       "      <th>...</th>\n",
       "      <th>Anomie</th>\n",
       "      <th>NegAff</th>\n",
       "      <th>PosAff</th>\n",
       "      <th>SureLw</th>\n",
       "      <th>If</th>\n",
       "      <th>NotLw</th>\n",
       "      <th>TimeSpc</th>\n",
       "      <th>FormLw</th>\n",
       "      <th>Othtags</th>\n",
       "      <th>Defined</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>H4Lvd</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DET ART</td>\n",
       "      <td>| article: Indefinite singular article--some o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ABANDON</td>\n",
       "      <td>H4Lvd</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Negativ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ngtv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SUPV</td>\n",
       "      <td>|</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ABANDONMENT</td>\n",
       "      <td>H4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Negativ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Noun</td>\n",
       "      <td>|</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ABATE</td>\n",
       "      <td>H4Lvd</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Negativ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SUPV</td>\n",
       "      <td>|</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ABATEMENT</td>\n",
       "      <td>Lvd</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Noun</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ABDICATE</td>\n",
       "      <td>H4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Negativ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SUPV</td>\n",
       "      <td>|</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ABHOR</td>\n",
       "      <td>H4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Negativ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hostile</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SUPV</td>\n",
       "      <td>|</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ABIDE</td>\n",
       "      <td>H4</td>\n",
       "      <td>Positiv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Affil</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SUPV</td>\n",
       "      <td>|</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ABILITY</td>\n",
       "      <td>H4Lvd</td>\n",
       "      <td>Positiv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Strong</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Noun</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ABJECT</td>\n",
       "      <td>H4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Negativ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Modif</td>\n",
       "      <td>|</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 186 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Entry Source  Positiv  Negativ Pstv  Affil  Ngtv  Hostile  Strong  \\\n",
       "0            A  H4Lvd      NaN      NaN  NaN    NaN   NaN      NaN     NaN   \n",
       "1      ABANDON  H4Lvd      NaN  Negativ  NaN    NaN  Ngtv      NaN     NaN   \n",
       "2  ABANDONMENT     H4      NaN  Negativ  NaN    NaN   NaN      NaN     NaN   \n",
       "3        ABATE  H4Lvd      NaN  Negativ  NaN    NaN   NaN      NaN     NaN   \n",
       "4    ABATEMENT    Lvd      NaN      NaN  NaN    NaN   NaN      NaN     NaN   \n",
       "5     ABDICATE     H4      NaN  Negativ  NaN    NaN   NaN      NaN     NaN   \n",
       "6        ABHOR     H4      NaN  Negativ  NaN    NaN   NaN  Hostile     NaN   \n",
       "7        ABIDE     H4  Positiv      NaN  NaN  Affil   NaN      NaN     NaN   \n",
       "8      ABILITY  H4Lvd  Positiv      NaN  NaN    NaN   NaN      NaN  Strong   \n",
       "9       ABJECT     H4      NaN  Negativ  NaN    NaN   NaN      NaN     NaN   \n",
       "\n",
       "  Power  ... Anomie NegAff PosAff SureLw   If NotLw TimeSpc FormLw  Othtags  \\\n",
       "0   NaN  ...    NaN    NaN    NaN    NaN  NaN   NaN     NaN    NaN  DET ART   \n",
       "1   NaN  ...    NaN    NaN    NaN    NaN  NaN   NaN     NaN    NaN     SUPV   \n",
       "2   NaN  ...    NaN    NaN    NaN    NaN  NaN   NaN     NaN    NaN     Noun   \n",
       "3   NaN  ...    NaN    NaN    NaN    NaN  NaN   NaN     NaN    NaN     SUPV   \n",
       "4   NaN  ...    NaN    NaN    NaN    NaN  NaN   NaN     NaN    NaN     Noun   \n",
       "5   NaN  ...    NaN    NaN    NaN    NaN  NaN   NaN     NaN    NaN     SUPV   \n",
       "6   NaN  ...    NaN    NaN    NaN    NaN  NaN   NaN     NaN    NaN     SUPV   \n",
       "7   NaN  ...    NaN    NaN    NaN    NaN  NaN   NaN     NaN    NaN     SUPV   \n",
       "8   NaN  ...    NaN    NaN    NaN    NaN  NaN   NaN     NaN    NaN     Noun   \n",
       "9   NaN  ...    NaN    NaN    NaN    NaN  NaN   NaN     NaN    NaN    Modif   \n",
       "\n",
       "                                             Defined  \n",
       "0  | article: Indefinite singular article--some o...  \n",
       "1                                                  |  \n",
       "2                                                  |  \n",
       "3                                                  |  \n",
       "4                                                NaN  \n",
       "5                                                  |  \n",
       "6                                                  |  \n",
       "7                                                  |  \n",
       "8                                                NaN  \n",
       "9                                                  |  \n",
       "\n",
       "[10 rows x 186 columns]"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inq = pd.read_excel('inquirerbasic.xls')\n",
    "inq.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entry\n",
      "ABATE\n",
      "True\n",
      "Source\n",
      "H4Lvd\n",
      "True\n",
      "Positiv\n",
      "nan\n",
      "False\n",
      "Negativ\n",
      "Negativ\n",
      "True\n",
      "Pstv\n",
      "nan\n",
      "False\n",
      "Affil\n",
      "nan\n",
      "False\n",
      "Ngtv\n",
      "nan\n",
      "False\n",
      "Hostile\n",
      "nan\n",
      "False\n",
      "Strong\n",
      "nan\n",
      "False\n",
      "Power\n",
      "nan\n",
      "False\n",
      "Weak\n",
      "nan\n",
      "False\n",
      "Submit\n",
      "nan\n",
      "False\n",
      "Active\n",
      "nan\n",
      "False\n",
      "Passive\n",
      "Passive\n",
      "True\n",
      "Pleasur\n",
      "nan\n",
      "False\n",
      "Pain\n",
      "nan\n",
      "False\n",
      "Feel\n",
      "nan\n",
      "False\n",
      "Arousal\n",
      "nan\n",
      "False\n",
      "EMOT\n",
      "nan\n",
      "False\n",
      "Virtue\n",
      "nan\n",
      "False\n",
      "Vice\n",
      "nan\n",
      "False\n",
      "Ovrst\n",
      "nan\n",
      "False\n",
      "Undrst\n",
      "nan\n",
      "False\n",
      "Academ\n",
      "nan\n",
      "False\n",
      "Doctrin\n",
      "nan\n",
      "False\n",
      "Econ@\n",
      "nan\n",
      "False\n",
      "Exch\n",
      "nan\n",
      "False\n",
      "ECON\n",
      "nan\n",
      "False\n",
      "Exprsv\n",
      "nan\n",
      "False\n",
      "Legal\n",
      "nan\n",
      "False\n",
      "Milit\n",
      "nan\n",
      "False\n",
      "Polit@\n",
      "nan\n",
      "False\n",
      "POLIT\n",
      "nan\n",
      "False\n",
      "Relig\n",
      "nan\n",
      "False\n",
      "Role\n",
      "nan\n",
      "False\n",
      "COLL\n",
      "nan\n",
      "False\n",
      "Work\n",
      "nan\n",
      "False\n",
      "Ritual\n",
      "nan\n",
      "False\n",
      "SocRel\n",
      "nan\n",
      "False\n",
      "Race\n",
      "nan\n",
      "False\n",
      "Kin@\n",
      "nan\n",
      "False\n",
      "MALE\n",
      "nan\n",
      "False\n",
      "Female\n",
      "nan\n",
      "False\n",
      "Nonadlt\n",
      "nan\n",
      "False\n",
      "HU\n",
      "nan\n",
      "False\n",
      "ANI\n",
      "nan\n",
      "False\n",
      "PLACE\n",
      "nan\n",
      "False\n",
      "Social\n",
      "nan\n",
      "False\n",
      "Region\n",
      "nan\n",
      "False\n",
      "Route\n",
      "nan\n",
      "False\n",
      "Aquatic\n",
      "nan\n",
      "False\n",
      "Land\n",
      "nan\n",
      "False\n",
      "Sky\n",
      "nan\n",
      "False\n",
      "Object\n",
      "nan\n",
      "False\n",
      "Tool\n",
      "nan\n",
      "False\n",
      "Food\n",
      "nan\n",
      "False\n",
      "Vehicle\n",
      "nan\n",
      "False\n",
      "BldgPt\n",
      "nan\n",
      "False\n",
      "ComnObj\n",
      "nan\n",
      "False\n",
      "NatObj\n",
      "nan\n",
      "False\n",
      "BodyPt\n",
      "nan\n",
      "False\n",
      "ComForm\n",
      "nan\n",
      "False\n",
      "COM\n",
      "nan\n",
      "False\n",
      "Say\n",
      "nan\n",
      "False\n",
      "Need\n",
      "nan\n",
      "False\n",
      "Goal\n",
      "nan\n",
      "False\n",
      "Try\n",
      "nan\n",
      "False\n",
      "Means\n",
      "nan\n",
      "False\n",
      "Persist\n",
      "nan\n",
      "False\n",
      "Complet\n",
      "nan\n",
      "False\n",
      "Fail\n",
      "nan\n",
      "False\n",
      "NatrPro\n",
      "nan\n",
      "False\n",
      "Begin\n",
      "nan\n",
      "False\n",
      "Vary\n",
      "nan\n",
      "False\n",
      "Increas\n",
      "nan\n",
      "False\n",
      "Decreas\n",
      "Decreas\n",
      "True\n",
      "Finish\n",
      "nan\n",
      "False\n",
      "Stay\n",
      "nan\n",
      "False\n",
      "Rise\n",
      "nan\n",
      "False\n",
      "Exert\n",
      "nan\n",
      "False\n",
      "Fetch\n",
      "nan\n",
      "False\n",
      "Travel\n",
      "nan\n",
      "False\n",
      "Fall\n",
      "nan\n",
      "False\n",
      "Think\n",
      "nan\n",
      "False\n",
      "Know\n",
      "nan\n",
      "False\n",
      "Causal\n",
      "nan\n",
      "False\n",
      "Ought\n",
      "nan\n",
      "False\n",
      "Perceiv\n",
      "nan\n",
      "False\n",
      "Compare\n",
      "nan\n",
      "False\n",
      "Eval@\n",
      "nan\n",
      "False\n",
      "EVAL\n",
      "nan\n",
      "False\n",
      "Solve\n",
      "nan\n",
      "False\n",
      "Abs@\n",
      "nan\n",
      "False\n",
      "ABS\n",
      "nan\n",
      "False\n",
      "Quality\n",
      "nan\n",
      "False\n",
      "Quan\n",
      "nan\n",
      "False\n",
      "NUMB\n",
      "nan\n",
      "False\n",
      "ORD\n",
      "nan\n",
      "False\n",
      "CARD\n",
      "nan\n",
      "False\n",
      "FREQ\n",
      "nan\n",
      "False\n",
      "DIST\n",
      "nan\n",
      "False\n",
      "Time@\n",
      "nan\n",
      "False\n",
      "TIME\n",
      "nan\n",
      "False\n",
      "Space\n",
      "nan\n",
      "False\n",
      "POS\n",
      "nan\n",
      "False\n",
      "DIM\n",
      "nan\n",
      "False\n",
      "Rel\n",
      "nan\n",
      "False\n",
      "COLOR\n",
      "nan\n",
      "False\n",
      "Self\n",
      "nan\n",
      "False\n",
      "Our\n",
      "nan\n",
      "False\n",
      "You\n",
      "nan\n",
      "False\n",
      "Name\n",
      "nan\n",
      "False\n",
      "Yes\n",
      "nan\n",
      "False\n",
      "No\n",
      "nan\n",
      "False\n",
      "Negate\n",
      "nan\n",
      "False\n",
      "Intrj\n",
      "nan\n",
      "False\n",
      "IAV\n",
      "IAV\n",
      "True\n",
      "DAV\n",
      "nan\n",
      "False\n",
      "SV\n",
      "nan\n",
      "False\n",
      "IPadj\n",
      "nan\n",
      "False\n",
      "IndAdj\n",
      "nan\n",
      "False\n",
      "PowGain\n",
      "nan\n",
      "False\n",
      "PowLoss\n",
      "nan\n",
      "False\n",
      "PowEnds\n",
      "nan\n",
      "False\n",
      "PowAren\n",
      "nan\n",
      "False\n",
      "PowCon\n",
      "nan\n",
      "False\n",
      "PowCoop\n",
      "nan\n",
      "False\n",
      "PowAuPt\n",
      "nan\n",
      "False\n",
      "PowPt\n",
      "nan\n",
      "False\n",
      "PowDoct\n",
      "nan\n",
      "False\n",
      "PowAuth\n",
      "nan\n",
      "False\n",
      "PowOth\n",
      "nan\n",
      "False\n",
      "PowTot\n",
      "nan\n",
      "False\n",
      "RcEthic\n",
      "nan\n",
      "False\n",
      "RcRelig\n",
      "nan\n",
      "False\n",
      "RcGain\n",
      "nan\n",
      "False\n",
      "RcLoss\n",
      "nan\n",
      "False\n",
      "RcEnds\n",
      "nan\n",
      "False\n",
      "RcTot\n",
      "nan\n",
      "False\n",
      "RspGain\n",
      "nan\n",
      "False\n",
      "RspLoss\n",
      "nan\n",
      "False\n",
      "RspOth\n",
      "nan\n",
      "False\n",
      "RspTot\n",
      "nan\n",
      "False\n",
      "AffGain\n",
      "nan\n",
      "False\n",
      "AffLoss\n",
      "nan\n",
      "False\n",
      "AffPt\n",
      "nan\n",
      "False\n",
      "AffOth\n",
      "nan\n",
      "False\n",
      "AffTot\n",
      "nan\n",
      "False\n",
      "WltPt\n",
      "nan\n",
      "False\n",
      "WltTran\n",
      "nan\n",
      "False\n",
      "WltOth\n",
      "nan\n",
      "False\n",
      "WltTot\n",
      "nan\n",
      "False\n",
      "WlbGain\n",
      "nan\n",
      "False\n",
      "WlbLoss\n",
      "nan\n",
      "False\n",
      "WlbPhys\n",
      "nan\n",
      "False\n",
      "WlbPsyc\n",
      "nan\n",
      "False\n",
      "WlbPt\n",
      "nan\n",
      "False\n",
      "WlbTot\n",
      "nan\n",
      "False\n",
      "EnlGain\n",
      "nan\n",
      "False\n",
      "EnlLoss\n",
      "nan\n",
      "False\n",
      "EnlEnds\n",
      "nan\n",
      "False\n",
      "EnlPt\n",
      "nan\n",
      "False\n",
      "EnlOth\n",
      "nan\n",
      "False\n",
      "EnlTot\n",
      "nan\n",
      "False\n",
      "SklAsth\n",
      "nan\n",
      "False\n",
      "SklPt\n",
      "nan\n",
      "False\n",
      "SklOth\n",
      "nan\n",
      "False\n",
      "SklTot\n",
      "nan\n",
      "False\n",
      "TrnGain\n",
      "nan\n",
      "False\n",
      "TrnLoss\n",
      "nan\n",
      "False\n",
      "TranLw\n",
      "TranLw\n",
      "True\n",
      "MeansLw\n",
      "nan\n",
      "False\n",
      "EndsLw\n",
      "nan\n",
      "False\n",
      "ArenaLw\n",
      "nan\n",
      "False\n",
      "PtLw\n",
      "nan\n",
      "False\n",
      "Nation\n",
      "nan\n",
      "False\n",
      "Anomie\n",
      "nan\n",
      "False\n",
      "NegAff\n",
      "nan\n",
      "False\n",
      "PosAff\n",
      "nan\n",
      "False\n",
      "SureLw\n",
      "nan\n",
      "False\n",
      "If\n",
      "nan\n",
      "False\n",
      "NotLw\n",
      "nan\n",
      "False\n",
      "TimeSpc\n",
      "nan\n",
      "False\n",
      "FormLw\n",
      "nan\n",
      "False\n",
      "Othtags\n",
      "SUPV\n",
      "True\n",
      "Defined\n",
      "|\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "s = inq[inq['Entry']=='ABATE'].to_dict()\n",
    "for k,v in s.items():\n",
    "    vv = list(v.values())[0]\n",
    "    print(k)\n",
    "    print(vv)\n",
    "    print(isinstance(vv,str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(inq[inq['Entry']==\"omar\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "186"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inq_categs = list(inq.columns)\n",
    "len(inq_categs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0, ...,   0,   0,   0],\n",
       "       [126, 126,   2, ...,   2, 126, 124],\n",
       "       [ 41,  41,   0, ...,   0,  41,  41],\n",
       "       ...,\n",
       "       [ 17,  17,   1, ...,   0,  17,  17],\n",
       "       [ 83,  83,   7, ...,   0,  83,  81],\n",
       "       [ 12,  12,   0, ...,   0,  12,  11]])"
      ]
     },
     "execution_count": 329,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "inq_features = np.zeros((1,len(inq_categs)),dtype=int)\n",
    "\n",
    "for review in data['review']:\n",
    "\n",
    "    inq_feat = dict.fromkeys(inq_categs,0)\n",
    "\n",
    "    for w in review.split(' '):\n",
    "\n",
    "        clean = w.strip().replace('.',\"\").replace(\"?\",'').replace(\",\",\"\").replace(\";\",'').upper()\n",
    "\n",
    "        # if the word exists in the dictionary\n",
    "        if len(inq[inq['Entry'] == clean]) > 0:\n",
    "            row = inq[inq['Entry']==clean].to_dict()\n",
    "            for k,v in row.items():\n",
    "                vv = list(v.values())[0]\n",
    "                if isinstance(vv,str):\n",
    "                    inq_feat[k] += 1\n",
    "                \n",
    "    # convert the dict to one row features \n",
    "    inq_feat_row = np.array(list(inq_feat.values()),dtype=int).reshape((1,len(inq_categs)))\n",
    "        \n",
    "    #combine with big matrix\n",
    "    inq_features = np.concatenate((inq_features,inq_feat_row),axis=0)\n",
    "    \n",
    "inq_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([32, 32,  1,  2,  1,  0,  2,  0,  2,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  1,  1,  2,  2,  3,  1,  0,  1,  0,  0,  0,  2,  2,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  1,  0,  0,  0,  0,  1,  0,  0,  2,  3,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  2,  0,  1,  0,  1,  1,  0,  2,  0,  0,  0,  0,  0,  0,\n",
       "        0,  2,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  4,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  1,  0,  0,  1,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  3,  3,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  1,  0,  0,  1,  0,  0,  1,  4,  0,  2, 32, 31])"
      ]
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inq_features[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('inq_features.csv',inq_features,delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine All feature extraction to one function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(reviews):\n",
    "    #Structural\n",
    "    #UGR\n",
    "    #GALC\n",
    "    #LIWC\n",
    "    #INQ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM with 1 feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[['length','rating']]\n",
    "y = data['rating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "model = SVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
       "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "    tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.25"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'avg_sent_length' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-393-e268faf1c877>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'hello omar.'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'I like this book omar'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'This is a nice book, Omar. I mean it'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mextract_features\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextract_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/code_local/review_helpfulness/extract_features.py\u001b[0m in \u001b[0;36mextract_features\u001b[0;34m(reviews, min_doc_freq)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mextract_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreviews\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmin_doc_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mstruct_extract\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreviews\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0mugr_extract\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreviews\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmin_doc_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmin_doc_freq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mgalc_extract\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreviews\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code_local/review_helpfulness/extract_features.py\u001b[0m in \u001b[0;36mstruct_extract\u001b[0;34m(reviews)\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'num_tokens'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreview\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'num_sentences'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreview\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m     \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'avg_sent_len'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreview\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mavg_sent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m     \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'num_exclm_mark'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreview\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'!'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ratio_q'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreview\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mper_of_q\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, convert_dtype, args, **kwds)\u001b[0m\n\u001b[1;32m   3846\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3847\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3848\u001b[0;31m                 \u001b[0mmapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_infer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3850\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/code_local/review_helpfulness/extract_features.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'num_tokens'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreview\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'num_sentences'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreview\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m     \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'avg_sent_len'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreview\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mavg_sent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m     \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'num_exclm_mark'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreview\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'!'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ratio_q'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreview\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mper_of_q\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'avg_sent_length' is not defined"
     ]
    }
   ],
   "source": [
    "import sys  \n",
    "sys.path.insert(0, '/feature_extractor')\n",
    "import extract_features\n",
    "\n",
    "a = ['hello omar.','I like this book omar','This is a nice book, Omar. I mean it']\n",
    "extract_features.extract_features(a)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
